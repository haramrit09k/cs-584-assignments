{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXZRgEyina_1"
   },
   "source": [
    "# Step 1: Data Preprocessing and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a Importing essential libraries and viewing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "ZHww9K17mvnQ",
    "outputId": "0e546f50-a5fb-4719-82a7-537a1bea521d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sentiment                                             review\n",
      "0              1  One of the other reviewers has mentioned that ...\n",
      "1              1  A wonderful little production. <br /><br />The...\n",
      "2              1  I thought this was a wonderful way to spend ti...\n",
      "3             -1  Basically there's a family where a little boy ...\n",
      "4              1  Petter Mattei's \"Love in the Time of Money\" is...\n",
      "...          ...                                                ...\n",
      "14994          1  *** out of ****<br /><br />Yep! Dressed To Kil...\n",
      "14995         -1  Bobcat Goldthwait should be commended for atte...\n",
      "14996          1  And it's not because since her days on \"Claris...\n",
      "14997         -1  A traveling couple (Horton and Hamilton)stumbl...\n",
      "14998         -1  This film is deeply disappointing. Not only th...\n",
      "\n",
      "[14999 rows x 2 columns]\n",
      "                                                  review\n",
      "0      This film should have never been made. Honestl...\n",
      "1      This movie was bad from the start. The only pu...\n",
      "2      God, I never felt so insulted in my whole life...\n",
      "3      Not being a fan of the Coen Brothers or George...\n",
      "4      The movie Andaz Apna Apna in my books is the t...\n",
      "...                                                  ...\n",
      "14987  Family Guy has to be my all time favorite cart...\n",
      "14988  This was a marvelously funny comedy with a gre...\n",
      "14989  There is no plot. There are no central charact...\n",
      "14990  This show is awesome! I love all the actors! I...\n",
      "14991  The fact that this movie has been entitled to ...\n",
      "\n",
      "[14992 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import statistics\n",
    "from statistics import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"1598639150_466036_train_file.txt\", sep=\"\\t\")\n",
    "print(train_data)\n",
    "\n",
    "test_data = pd.read_csv(\"1598639150_4984343_test_file.txt\", header=None, names=[\"review\"])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Ensuring test dataset has expected number of entries i.e. 15000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing the test set: size =  14992\n",
      "After preprocessing the test set: size =  15000\n"
     ]
    }
   ],
   "source": [
    "print(\"Before preprocessing the test set: size = \", test_data.size)\n",
    "f = open(\"1598639150_4984343_test_file.txt\", 'r', encoding=\"utf8\")\n",
    "txt = f.read().split('\\n')\n",
    "txt = list(filter(None, txt))\n",
    "test_data = pd.DataFrame(txt, columns=['review'])\n",
    "print(\"After preprocessing the test set: size = \", test_data.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaDSoC4c6FO1"
   },
   "source": [
    "## 1.c Check for null values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "76bJuag65seR",
    "outputId": "309461ac-fb1e-4633-b985-b53ccd34ebd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in train set:\n",
      " sentiment    0\n",
      "review       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Number of null values in test set:\n",
      " review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values in train set:\\n\",train_data.isnull().sum())\n",
    "print(\"\\n\\nNumber of null values in test set:\\n\",test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8MvP8VMrC_S"
   },
   "source": [
    "## 1.d Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "9E8QUGAp9FXB",
    "outputId": "1fcf83d5-0af9-4d4a-ccea-37798a9dfa6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/haramrit09k/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/haramrit09k/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZ6DMsIL8eHS"
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stopwords.append('br') # to remove br tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to lower case\n",
    "train_data['review'] = train_data['review'].str.lower()\n",
    "# Remove all characters that are not alphabets\n",
    "train_data['review'] = train_data['review'].str.replace('[^a-zA-Z ]', ' ')\n",
    "# Lemmatization, removal of stopwords and only accepting words with length greater than equal to 2\n",
    "train_data['review'] = train_data['review'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stopwords and len(word) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to lower case\n",
    "test_data['review'] = test_data['review'].str.lower()\n",
    "# Remove all characters that are not alphabets\n",
    "test_data['review'] = test_data['review'].str.replace('[^a-zA-Z ]', ' ')\n",
    "# Lemmatization, removal of stopwords and only accepting words with length greater than equal to 2\n",
    "test_data['review'] = test_data['review'].apply(lambda x : ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stopwords and len(word) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    one reviewer mentioned watching oz episode hoo...\n",
      "1    wonderful little production filming technique ...\n",
      "2    thought wonderful way spend time hot summer we...\n",
      "3    basically family little boy jake think zombie ...\n",
      "4    petter mattei love time money visually stunnin...\n",
      "5    probably time favorite movie story selflessnes...\n",
      "6    sure would like see resurrection dated seahunt...\n",
      "7    show amazing fresh innovative idea first aired...\n",
      "8    encouraged positive comment film looking forwa...\n",
      "9    like original gut wrenching laughter like movi...\n",
      "Name: review, dtype: object\n",
      "0    film never made honestly must admit saw seriou...\n",
      "1    movie bad start purpose movie angela wanted ge...\n",
      "2    god never felt insulted whole life crap many w...\n",
      "3    fan coen brother george clooney anyone see ske...\n",
      "4    movie andaz apna apna book top intelligent com...\n",
      "5    say really looking forward watching film findi...\n",
      "6    film powerfully demonstrates struggle two woma...\n",
      "7    first minute movie make fun sequel pg movie re...\n",
      "8    susie original like bad disney film spoiler bo...\n",
      "9    series dinosaurus lived million year ago dinos...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Viewing first 10 elements of train dataset to confirm the cleaning process\n",
    "print(train_data['review'][:10])\n",
    "# Viewing first 10 elements of test dataset to confirm the cleaning process\n",
    "print(test_data['review'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.e Perform TFIDF vectorization of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "Llki2zKF_0n-",
    "outputId": "14222264-ff9a-4b5a-ce03-710dd13f9dde"
   },
   "outputs": [],
   "source": [
    "# initialize TFIDF vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,3), max_features = 75000)\n",
    "# fit and transform the vectorizer on the training dataset\n",
    "vectorizer.fit(train_data['review'])\n",
    "train_vector = vectorizer.transform(train_data['review'])\n",
    "# transform the vectorizer on the testing dataset\n",
    "test_vector = vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 75000) (15000, 75000) (14999,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_vector\n",
    "X_test = test_vector\n",
    "y_train = train_data['sentiment']\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# converted y_train to numpy array to resolve error I faced while calculating the cosine similarity\n",
    "y_train = y_train.to_numpy()\n",
    "print(y_train.shape)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Implementing the KNN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a Calculating cosine similarity between X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "MWsGZ7dTlIXq",
    "outputId": "5b876a10-6181-4151-9635-2e51583671c6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(15000, 14999)\n",
      "[[0.01886262 0.01033139 0.02266331 ... 0.00926203 0.02210489 0.02098045]\n",
      " [0.02660679 0.01075998 0.0016965  ... 0.0114348  0.00502515 0.01075864]\n",
      " [0.0281239  0.03783957 0.02371897 ... 0.00909485 0.02239779 0.02775007]\n",
      " ...\n",
      " [0.01195106 0.06832874 0.01023805 ... 0.00485011 0.03405178 0.01403564]\n",
      " [0.03929119 0.02227215 0.01832944 ... 0.03110629 0.00766168 0.03120383]\n",
      " [0.00903945 0.02842507 0.03901048 ... 0.01157718 0.00698245 0.02970456]]\n"
     ]
    }
   ],
   "source": [
    "cos_sim = cosine_similarity(X_train, X_test)\n",
    "cos_sim = cos_sim.transpose() #transpose operation to have the test set elements as rows for easier iteration\n",
    "print(type(cos_sim))\n",
    "print(cos_sim.shape)\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Find the k nearest neighbours from the cosine similarity matrix for each test item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gy7DhoEajL26"
   },
   "outputs": [],
   "source": [
    "indices = list()\n",
    "k = 299 # Best value of k chosen after experimenting\n",
    "for doc in cos_sim:\n",
    "    indices.append(np.argsort(doc)[-k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HttNN-N6snQF",
    "outputId": "c866316b-41cd-473c-d18d-9e175a04d250",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    }
   ],
   "source": [
    "# Print length of an item in indices list to ensure it has k values\n",
    "print(len(indices[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c Find predicted value of each test item using majority voting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "UkzaAVDhkI9t",
    "outputId": "83864252-0196-4d6f-a2a4-7f4bbcb6eda6"
   },
   "outputs": [],
   "source": [
    "pred_val = list()\n",
    "for arr in indices:\n",
    "    pred_val.append(mode([y_train[i] for i in arr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGhvc5wJkm1O",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "# Printing length of pred_val to ensure correct number of test set items were predicted i.e. 15000\n",
    "print(len(pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.d Write predicted values to a text file in the requested format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 15000 items successfully to pred_values.txt\n"
     ]
    }
   ],
   "source": [
    "with open('pred_values.txt', 'w') as filehandle:\n",
    "    for listitem in pred_val:\n",
    "        filehandle.write('%s\\n' % listitem)\n",
    "    print(\"Wrote\",len(pred_val),\"items successfully to pred_values.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cs584_hw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
